{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful Soup 예제 1\n",
    "from bs4 import BeautifulSoup\n",
    "ex1 = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title> HTML 연습 </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p align=\"center\"> text 1 </p>\n",
    "        <img src=\"c:\\\\temp\\\\image\\\\솔개.png\">\n",
    "    </body>\n",
    "<html> '''\n",
    "\n",
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "print( soup.find('title') ) # find('태그명', 속성명='속성값')\n",
    "print( soup.find('p') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4598e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful Soup 예제 2\n",
    "from bs4 import BeautifulSoup\n",
    "ex1 = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title> HTML 연습 </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p align=\"center\"> text 1 </p>\n",
    "        <p align=\"right\"> text 2 </p>\n",
    "        <p align=\"left\"> text 3 </p>\n",
    "        <img src=\"c:\\\\temp\\\\image\\\\솔개.png\">\n",
    "    </body>\n",
    "<html> '''\n",
    "\n",
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "print( '첫번째 태그만 추출:',soup.find('p') )\n",
    "print( '속성값을 지정하여 추출:', soup.find('p',align=\"right\") )\n",
    "print( '속성값을 지정하여 추출:', soup.find(\"head\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3899a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두번째가져오기: <p align=\"center\"> text 2 </p>\n"
     ]
    }
   ],
   "source": [
    "#Beautiful Soup 예제 3\n",
    "from bs4 import BeautifulSoup\n",
    "ex1 = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title> HTML 연습 </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p align=\"center\"> text 1 </p>\n",
    "        <p align=\"center\"> text 2 </p>\n",
    "        <p align=\"center\"> text 3 </p>\n",
    "        <img src=\"c:\\\\temp\\\\image\\\\솔개.png\">\n",
    "    </body>\n",
    "<html> '''\n",
    "\n",
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "# print( '1건만가져오기:', soup.find('p') ) \n",
    "# print( '전부가져오기:', soup.find_all('p') )\n",
    "# print( '첫번째가져오기:',soup.find_all('p')[0] )\n",
    "print( '두번째가져오기:',soup.find_all('p')[1] )\n",
    "# print( '세번째가져오기:',soup.find_all('p')[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa13d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select( ) 함수 사용하기\n",
    "# 연습용 html 만들기\n",
    "ex2='''\n",
    "<html>\n",
    "    <head>\n",
    "        <h1> 사야할 과일\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1> 시장가서 사야할 과일 목록\n",
    "            <div><p id='fruit1' class='name1' title='바나나'> 바나나\n",
    "                <span class='price'> 3000원 </span>\n",
    "                <span class='count'> 10개 </span>\n",
    "                <span class='store'> 바나나가게 </span>\n",
    "                <a href='https://www.banana.com'> banana.com </a>\n",
    "                </p>\n",
    "            </div>\n",
    "             <div><p id='fruit2' class='name2' title='체리'> 체리\n",
    "                <span class='price'> 100원 </span>\n",
    "                <span class='count'> 50개 </span>\n",
    "                <span class='store'> 체리가게 </span>\n",
    "                <a href='https://www.cherry.com'> cherry.com </a>\n",
    "                </p>\n",
    "            </div>\n",
    "             <div><p id='fruit3' class='name3' title='오렌지'> 오렌지\n",
    "                <span class='price'> 500원 </span>\n",
    "                <span class='count'> 20개 </span>\n",
    "                <span class='store'> 오렌지가게 </span>\n",
    "                <a href='https://www.orange.com'> orange.com </a>\n",
    "                </p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html> '''           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28546445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select('태그이름')\n",
    "soup2 = BeautifulSoup(ex2 , 'html.parser')\n",
    "\n",
    "soup2.select('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select(''.클래스이름')\n",
    "soup2.select('.name1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select(‘ 상위태그 > 하위태그 > 하위태그‘ )\n",
    "soup2.select(' div > p > span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ade809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select(‘상위태그.클래스이름 > 하위태그.클래스이름’)\n",
    "soup2.select(' p.name1 > span.store ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "617c5cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"name1\" id=\"fruit1\" title=\"바나나\"> 바나나\n",
       "                 <span class=\"price\"> 3000원 </span>\n",
       " <span class=\"count\"> 10개 </span>\n",
       " <span class=\"store\"> 바나나가게 </span>\n",
       " <a href=\"https://www.banana.com\"> banana.com </a>\n",
       " </p>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select(‘#아이디명”)\n",
    "soup2.select(' #fruit1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a5cddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.banana.com\"> banana.com </a>,\n",
       " <a href=\"https://www.cherry.com\"> cherry.com </a>,\n",
       " <a href=\"https://www.orange.com\"> orange.com </a>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select(‘태그명[속성1=값1]’)\n",
    "soup2.select('a[href]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ad2b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"name1\" id=\"fruit1\" title=\"바나나\"> 바나나\n",
      "                <span class=\"price\"> 3000원 </span>\n",
      "<span class=\"count\"> 10개 </span>\n",
      "<span class=\"store\"> 바나나가게 </span>\n",
      "<a href=\"https://www.banana.com\"> banana.com </a>\n",
      "</p>\n",
      "<p class=\"name2\" id=\"fruit2\" title=\"체리\"> 체리\n",
      "                <span class=\"price\"> 100원 </span>\n",
      "<span class=\"count\"> 50개 </span>\n",
      "<span class=\"store\"> 체리가게 </span>\n",
      "<a href=\"https://www.cherry.com\"> cherry.com </a>\n",
      "</p>\n",
      "<p class=\"name3\" id=\"fruit3\" title=\"오렌지\"> 오렌지\n",
      "                <span class=\"price\"> 500원 </span>\n",
      "<span class=\"count\"> 20개 </span>\n",
      "<span class=\"store\"> 오렌지가게 </span>\n",
      "<a href=\"https://www.orange.com\"> orange.com </a>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "# 태그 뒤의 텍스트만 추출하기 \n",
    "txt3 = soup2.find_all('p')\n",
    "for i in txt3 :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a302280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 바나나                 3000원  10개  바나나가게  banana.com \n",
      " 체리                 100원  50개  체리가게  cherry.com \n",
      " 오렌지                 500원  20개  오렌지가게  orange.com \n"
     ]
    }
   ],
   "source": [
    "# 태그 뒤의 텍스트만 추출하기 \n",
    "txt3 = soup2.find_all('p')\n",
    "for i in txt3 :\n",
    "    print(i.get_text().replace('\\n','') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77480319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 riss 사이트의 논문 자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "1   국제보건규칙 개정에 따른 우리나라 검역전염병 지정방안  김윤호 경북대학교 보건대학원 2007 국내석사  RANK : 27772927    원문보기 목차검색조회 음성듣기             국제보건규칙 개정에 따라 우리나라 검역전염병의 수정이 필요한 시점에 우리나라의 검역전염병의 지정근거를 제시하기 위하여 우리나라와 세계주요국의 검역전염병, 해외유입전염병 중 일부, 세계보건규칙에 예시된 전염병을 중심으로 검토하였다. 치명률, 유행가능성, 예방접종효과, 격리효과, 국내해외유입전염병 발생 유무, 검역적용여부 등 6가지 항목을 고려한 검역전염병 지정타당도를 개발 적용하였다 본 연구결과를 요약하면 다음과 같다.   첫째 우리나라 검역전염병은 국제보건규칙에서 정한 검역전염병과 똑같은 변화과정을 거쳤다. 다른나라의 경우 세계보건규칙에서 정한 검역전염병 이외에 주변국의 전염병발생현황 및 자국에 맞는 검역전염병을 지정운영하여 왔다.   둘째 우리나라와 중국을 제외한 미국, 일본, 호주, 캐나다에서는 에볼라, 콩고크리미아 출혈열등 바이러스성 출혈열을 검역대상 전염병으로 관리하고 있었다.   셋째 우리나라에서는 검역전염병으로 지정하고 있지 않으나 다른나라에서 검역법에 규정하고 있는 질병은 바이러스출혈, 세계적으로 박멸을 선언했던 천연두, 디프테리아, 홍역, 유행성이하선염, 신증후성출혈열, 리프트계곡열등 28종이다.   넷째. 일본와 중국은 검역전염병이외의  질병발생을 감시하기 위해 검역법에 그 대상을 명시하고 있었다.   다섯째 검토대상질병을 대상으로 지정타당도를 적용한 결과 결핵, 보툴리누스증, 야토병은 각1점을 유행가능성은 높지만 예방접종이나 격리가 이 병의 전파방지에 도움이 되지 않기 때문에 지정타당도 점수가 낮은 콜레라를 비롯하여 천연두, 라싸열, 웨스트나일열, 재귀열, 인플루엔자, 탄저는 2점 이다. 3점은 황열, 마르부르그병, 콩코크리미아, 에볼라, 사스, 뎅기열, 말라리아, 일본뇌염, 한타바이러스폐증후군, 폴리오, 홍역, 공수병이며 디프테리아, 조류인플루엔자 인체감염, 신증후성출혈열, 장티푸스, 수막구균성수막염, 리프트계곡열이 4점을 받고 페스트, 유행선이하선염이 5점을 받았다. A형유행성독감은 치명률을 알 수 없어 지정타당도 점수를 구하지 못하였다.   본 연구를 토대로 지정타당도 점수에서 2점을 받은 전염병 중 전염병예방법 제1군전염병을 검역전염병으로 3점이상을 받은 전염병 중 전염병예방법의 제2군전염병은 감시전염병으로 지정하고 그 이외 3점이상을 받은 전염병을 검역전염병으로 추가지정 운영을 제안해 본다.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      " Finally, this study examines the relationship between potential tourists' perception of risk for overseas travel, media reports, and social media, and the influence of the image of the region or country as a tourist destination on tourism decision-making and selection in a crisis caused by the outbreak and spread of an infectious disease. It is meaningful to resume international and domestic travel, improving the country image, and offer countermeasures in case of an epidemic by identifying and figuring out the moderating effect of tourists' interest in overseas travel and the degree of involvement, which is important.tion activities should be prepared. In addition, preemptive tourism policy proposals for the revitalization of the international and domestic tourism market in the post-epidemic era from the aspect of local society, travel agencies and companies, country government, and organizational aspects between governments and institutions can respond to epidemic outbreaks. And established a cooperative institutionalized and managed system between governments and institutions and suggested ways to keep infectious diseases controllable. Finally, in consideration of the problems found during the course of this study, research tasks that can be supplemented in future follow-up studies were derived.sting hypothesis 5 “There will be an interactional effect of involvement between country image and behavioral intention” as the result of testing, there has a difference in the path of the relationship between risk perception and behavioral intention between the the high-involvement group and low-involvement group, and also there was a difference in the path of the influence relationship between the country image and behavioral intention, and that the degree of involvement had an interactional effect in the two pathways.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      " 마지막으로 SNS 사용 정도에 따라 전염병 위험 지각과 관광행동에 간의 영향 관계에 있어서 차이가 있는지 보았다. 이는 저사용 집단의 경우, 전염병에 대한 정보를 찾아보고 체계적으로 생각하는 것이 관광행동에 영향을 미치고 있었다. 한편 고사용 집단의 경우, 전염병에 대한 정보를 찾아본다거나 체계적으로 생각해서 그 판단에 의해 관광행동을 결정하는 것이 아니라 위험에 대한 지각이 직접적으로 관광을 하고자 하는 행동에 영향을 미치고 있는 것으로 확인되었다. 따라서 전염병에 대한 정보를 찾아보는 SNS 저사용 집단을 위해서는 TV나 문자, 신문, 방송을 통해 전염병에 대한 정보를 전달하는 것이 중요하다고 볼 수 있으며, 반면 SNS 고사용자를 위해서는 SNS를 통해서 전염병에 대한 최신 정보 및 정확한 정보를 SNS를 통해서 전달하는 것이 중요할 것으로 확인되었다.타격을 주게 된다. 한국관광공사는 2020년 3월 해외여행 목적의 출국자가 전년도 동월보다 93.9% 감소하였으며, 국내 입국자 역시 95%로 급감한 것으로 확인하였다.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      " In this paper, we will conduct in-depth research on the Prevention of hospital infection of respiratory infectious diseases, and in the future, we will conduct in-depth research on more hospitals to avoid and reduce hospital infection. It is hoped that the study will contribute to the avoidance and reduction of hospital infections of respiratory infectious diseases.xample analysis. According to the evaluation results and the actual specific situation of the hospital, preventive measures are put forward according to the hospital infection prevention standard level.Before the risk of nosocomial infection is serious, one pedestrian line and one motor vehicle line are set in the hospital. The underground access line to the treatment area is closed, which can reserve an entrance to the treatment area.When the risk of nosocomial infection is serious, the space is transformed. This can integrate the treatment area into a treatment area. A ground entrance is provided which can close the underground parking lot. In the common area of the diagnosis and treatment area, a spatial transformation was carried out to allow patients to enter the diagnosis and treatment unit by the side of the corridor. When the risk of infection is particularly serious, the emergency department, outpatient department, examination room and ward of key diagnosis and treatment units can be transformed through the space, so that patients can enter the diagnosis and treatment room from one side of the corridor. At the same time, the spatial analysis parameters reach the ideal value of prevention.s and treatment unit, select the highest connection value, the highest control value, the average depth, the average degree of integration, comprehensibility, and plotted into a comprehensive data map.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      " 재난은 국민에게 유리한 정치적 판단을 통하여 빠르게 수습하는 것이 중요하다 할 수 있으며 현대 재난에 있어서 특히 신속하고 실리적인 방법을 통해 재난을 극복해야 한다는 점을 명심하여야 할 것이다.대전 사망자 5,646만 명의 12% 수준으로 단기간(3년) 질병에 의한 피해가 전 세계 전쟁(5년)의 피해에 필적할 정도여서 인류의 역사는 전쟁보다는 복합재난으로서 질병, 감염병 재난이 더욱 심각하다. 그 심각한 피해에 대하여 깊이 생각하고 전 세계적으로 대응할 필요가 있다.  재난인 전쟁과 천연두, 대기근 등 자연 재난에 대한 인적 손실은 전사, 피로인 10만 7천 명 대 천연두 73만 명, 대기근 227만 명 합계 300만 명으로 30배에 이르는 것을 확인할 수 있었다. 전쟁이라는 충격적 사회재난은 단기간에 걸친 정치적 행위로서 역사에 기록되나, 감염병, 기근 등 자연 재난은 복합적 요인으로 장기간에 걸쳐 발생되고 정확한 기록이나 자료가 미비하여 시간이 경과하면 망각 되지만 실제로 그 피해 규모 등은 전염병 재난이 사회재난인 전쟁의 7배, 대기근까지 포함하면 30배에 달하고 있다.  spond globally.ificial uprising was separated from the suffering of the people, causing the greatest humiliation in the shortest period of time in history. Human losses due to natural disasters such as war, smallpox, and famine, which are social disasters, were confirmed to reach 30 times, with 107,000 warriors and fatigue, 730,000 smallpox, and 2.27 million famine totaling 3 million. Shocking social disasters such as war are recorded in history as political acts over a short period of time, but natural disasters such as infectious diseases and famine occur over a long period of time due to complex factors, and are forgotten over time due to insufficient accurate records or data. The number of infectious disease disasters is 7 times greater than that of war, a social disaster, and 30 times greater if famine is included.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      "6   전염병과 펜데믹 상황에서 메디컬 처치의 운영에 관한 연구  이재훈 칼빈대학교 신학대학원 2021 국내석사  RANK : 27772927    원문보기 목차검색조회 음성듣기\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      "     키워드: 전염병 안전관리체계, 지역공동체, 이해관계자, 서비스 플랫폼 디자인서비스 플랫폼의 디자인방안을 제시한다. 플랫폼의 프레임워크 디자인을 자세히 설명하고 UI 프로토타입 디자인를 통해 메인 페이지 기능, 주변 지역공동체 전염병 검색, 의료 기능 및 개인 정보 등 주요 기능의 디자인 계획을 보여준다. 이 디자인은 지역 주민에게 보다 안전하고 편리하며 신뢰할 수 있는 서비스를 제공하고 전염병 예방 및 통제 작업의 효과적인 구현을 돕는 것을 목표로 한다. 해, 중국의 전염병 현황 및 중국에서 코로나-19 바이러스가 빠 르게 퍼진 이유를 포함하여 파악하였다. 또한 전염병 확산 방지를 위한 안전관리체계에 대한 이론적 검토를 거쳐 그 개념과 구성요소를 명확히 하였다.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      " 연구자는 전염병으로 인해 변화되고 있는 일상을 글과 그림으로 기록해왔으며, 이를 사회적 상황과 연관 지어 연구하였다. 이러한 작업은 전염병에서 생존하고 적응하며, 전염병을 극복하기 위한 개인의 노력이기도 하며, 동시대인에게 위로와 공감을 제공할 수 있을 것으로 기대한다. 그뿐만 아니라 바이러스 확산 시점부터 여태까지의 일상의 행적을 돌아봄을 통해 앞으로의 미래는 어떨지 예상해보며, 현재의 일상에 대한 표현연구가 미래의 일상을 준비하기 위한 이정표가 되기를 기대한다.착용하는 마스크의 답답함을 바닷속에서 호흡하는 것과 같다는 연관성을 가지고 전체적으로 블루 색상으로 표현하였다. 둘째, 특정 식자재, 의료용품 등 특정 소비재의 과잉 구매 현상이다. 코로나의 장기화로 인한 사람들의 불안감은 특정 물품들을 과잉 구매하는 방식으로 표출되기도 하였으며, 특정 물품들은 판매량이 급증하기도 했다. 이 과정에서 연구자의 가족이 겪게 된 변화된 일상의 모습을 연구자의 주관적 색채로 표현하였다. 셋째, 사람들의 시사 전반에 대한 의식 변화이다. 평소 시사에 관심이 없던 사람들도 해외, 국내의 확진 현황, 확진자의 동선 등을 확인하기 위해 뉴스를 시청하거나 휴대전화를 확인하는 일이 많아졌고 이는 시사 전반에 대한 관심으로 이어지기도 했다. 이러한 시기에 미디어의 보도를 통해 현실을 인식하게 되는 연구자 가족의 모습을 연구작을 통해 표현함과 동시에 미디어 보도의 수용과정에서 있을 수 있는 부작용에 대해 고찰해보았다. 넷째, 집콕 여가생활 등의 취미 변화이다. 외출하지 않고도 집에서 카페 느낌을 낼 수 있는 홈카페 문화가 형성되기도 하였고, 반려식물을 기르는 등 실내에서 할 수 있는 여가활동이 증가했다. 아울러 여행, 나들이의 행태도 달라졌다. 연구자는 변화된 취미생활에 적응하며 이러한 상황을 작업으로 표현하였다.ould serve as an opportunity to predict the future by looking back on quotidian aspects from the outbreak and spread of COVID-19 and this study on present aspects of daily life would be a milestone to prepare future aspects of daily life. 과거부터 전염병은 정치. 문화, 사회, 생활 면에서 많은 변화를 가져왔다. 갑작스럽게 찾아오는 재난으로서 전염병의 창궐은 모든 사람들을 큰 충격에 빠뜨리게 한다. 그로 인한 급격한 환경변화는 날마다 반복되던 평범한 일상에 영향을 주고 특별한 경험을 하게 한다. 이러한 전염병의 시대를 살아가는 개인의 일상생활을 탐구하는 것은 시대의 흐름을 읽어내고 앞으로의 변화에 대비할 수 있도록 하는 의미가 있다.ent affairs. I portrayed aspects of my family who perceive realities through media coverage and considered the side effects that might be brought on in the course of embracing media reports. The fourth is the change in pursuit of leisure or hobbies. A home café culture has been created and leisure activities including growing plants at home have increased. Aspects of traveling and outing have also changed. I represented this situation, adapting quickly to an altered hobby life. \n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      "9   전염병에 대한 기독교 견해와 고찰  이성훈 칼빈대학교 신학대학원 2021 국내석사  RANK : 27772927    원문보기 목차검색조회 음성듣기\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n",
      "목차검색조회\n",
      "\n",
      "\n",
      "음성듣기\n",
      "\n",
      "\n",
      "   이 논문은 식민지시기의 텍스트를 중심으로 문학과 의학, 질병과 위생의 문제를 다시 읽고자 한 것이다. 또한 1920-30년대 개인의 기록을 독해하기 위하여 19세기 후반 근대의학의 발달 경로와 반응, 담론장의 형성을 함께 살펴보았다. 과거의 전염병 기억을 톺아보는 작업은 ‘지금-여기’를 살아가는 이들에게도 중요하다. 팬데믹이라는 급박한 위기 상황에 대처하는 근대의학의 ‘효율적인’ 기획은 현재에도 이어지고 있으며, 인간이 질병으로 인해 고통받는 것은 시·공간을 초월하는 문제이기 때문이다. 최근 전 세계가 경험한 팬데믹은 미증유의 사건이 아니다. 인류가 특정 질병에 대응하는 방식은 ‘불쑥’ 생겨난 것이 아니라, 과거로부터 이어진 전염병의 기억과 기록으로부터 출발한다. 의학과 과학의 적절한 역할 수행으로 이루어진 치밀한 방역과 발빠른 대처는 질병의 ‘의도 없는’ 폭력으로부터 해방되고자 한 성과다. 그러나 전염병 방역의 ‘성공’이 과연 ‘모두의 승리’로 이어질 수 있는지, 본 논문은 작은 질문을 남겨두고자 하는 것이다. 그 ‘승리’의 과정에 스러져간 개인들의 이야기를 복원하고 기억하려는 시도를 통해, 새로이 다가올 팬데믹에 대한 하나의 시좌를 제공해줄 수 있으리라 기대한다.suffering caused by disease transcends specific historical or spatial contexts, and the recent global pandemic should not be regarded as an entirely unprecedented event. Rather, contemporary responses to disease are grounded in historical experiences and collective memories of past epidemics. The implementation of precise quarantine systems and rapid interventions reflects efforts to counter the non-intentional violence of illness through the rational frameworks of medicine and science. However, this study raises a critical question: can the “success” of epidemic control be regarded as a “universal” victory? By recovering and reexamining the narratives of individuals marginalized or erased in this process, this thesis aims to offer a perspective for reflecting on future pandemics. 본 논문은 식민지 조선에서 결핵을 직접 혹은 간접적으로 체험한 작가들의 텍스트에 재현된 전염병 유행 사회와 개인의 존재 양상을 분석한다. 이를 통해 근대의학적 제도와 담론이 개인의 정체성 형성에 개입하는 방식을 추적하고, 나아가 의학적 통계에 드러나지 않는 환자 개인의 경험과 감각을 문학 텍스트를 통하여 복원하고자 시도하였다. 근대의학과 위생 담론이 주도하였던 병든 개인의 소외는 그들의 환자 정체성을 구성하였다. 팬데믹이라는 위기 상황 아래에서 질병을 이환시킬 수 있는 ‘가능성’을 가진 모든 신체는 감시와 통제의 대상이 되었으며, 부국강병의 논리를 앞세운 위생 담론은 ‘합법적’ 통제 과정의 폭력을 정당화했다. 또한 비정상적 신체를 향한 차별과 처벌은 그들을 쓸모 없고 위험한 존재로 낙인찍었다. 본고는 비정상의 신체를 재현한 나도향·이태준, 김유정·안회남의 식민지시기 텍스트를 전염병 유행 사회 속 개인의 증언이면서, 환자의 정체성을 (재)구성할 수 있는 사료라고 본다. 이를 위해 간호학의 ‘이야기적 이해’(narrative understading) 개념을 전유한다.\n",
      "\n",
      "\n",
      "원문보기\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3차시 : riss.kr 사이트에서 특정 키워드로 자동 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time          \n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 riss 사이트의 논문 자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 전염병): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"c:/chromedriver-win64/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://www.riss.kr/'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "driver.maximize_window()\n",
    "\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'query')\n",
    "driver.find_element(By.ID,'query').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "\n",
    "#Step 5.학위 논문 선택하기\n",
    "driver.find_element(By.LINK_TEXT,'학위논문').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 6.Beautiful Soup 로 본문 내용만 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('div','srchResultListW').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e6493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
